{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2489 - acc: 0.9225 - val_loss: 0.1049 - val_acc: 0.9669\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1020 - acc: 0.9693 - val_loss: 0.0881 - val_acc: 0.9753\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0767 - acc: 0.9769 - val_loss: 0.0722 - val_acc: 0.9794\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0611 - acc: 0.9819 - val_loss: 0.0758 - val_acc: 0.9787\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0506 - acc: 0.9848 - val_loss: 0.0673 - val_acc: 0.9816\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0438 - acc: 0.9872 - val_loss: 0.0687 - val_acc: 0.9827\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0390 - acc: 0.9884 - val_loss: 0.0803 - val_acc: 0.9818\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0355 - acc: 0.9899 - val_loss: 0.0930 - val_acc: 0.9795\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0308 - acc: 0.9910 - val_loss: 0.0856 - val_acc: 0.9826\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0883 - val_acc: 0.9827\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0260 - acc: 0.9927 - val_loss: 0.0924 - val_acc: 0.9825\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0279 - acc: 0.9924 - val_loss: 0.1023 - val_acc: 0.9815\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.1062 - val_acc: 0.9805\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0225 - acc: 0.9937 - val_loss: 0.1060 - val_acc: 0.9832\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0228 - acc: 0.9942 - val_loss: 0.0978 - val_acc: 0.9839\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0211 - acc: 0.9942 - val_loss: 0.1132 - val_acc: 0.9819\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0209 - acc: 0.9945 - val_loss: 0.1118 - val_acc: 0.9832\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.1058 - val_acc: 0.9838\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.1042 - val_acc: 0.9834\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0214 - acc: 0.9945 - val_loss: 0.0995 - val_acc: 0.9840\n",
      "Test loss: 0.0994848745454959\n",
      "Test accuracy: 0.984\n",
      "90.106415987\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.7241 - acc: 0.5070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.7064 - acc: 0.5080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6973 - acc: 0.5270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6916 - acc: 0.5380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.6869 - acc: 0.5570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6835 - acc: 0.5790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6814 - acc: 0.5650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6749 - acc: 0.5830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6719 - acc: 0.5890\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6684 - acc: 0.6150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120ea1d10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 2.3569 - acc: 0.0900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 2.3136 - acc: 0.1110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.3009 - acc: 0.1240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.2908 - acc: 0.1320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.2814 - acc: 0.1430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.2737 - acc: 0.1460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.2645 - acc: 0.1650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.2556 - acc: 0.1530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 2.2479 - acc: 0.1680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 2.2381 - acc: 0.1730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120e8dc10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "11501568/11490434 [==============================] - 3s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2473 - acc: 0.9241 - val_loss: 0.1176 - val_acc: 0.9646\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1025 - acc: 0.9695 - val_loss: 0.0947 - val_acc: 0.9710\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0751 - acc: 0.9769 - val_loss: 0.0816 - val_acc: 0.9778\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0622 - acc: 0.9813 - val_loss: 0.0873 - val_acc: 0.9733\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0529 - acc: 0.9844 - val_loss: 0.0720 - val_acc: 0.9821\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0450 - acc: 0.9868 - val_loss: 0.0743 - val_acc: 0.9836\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0391 - acc: 0.9887 - val_loss: 0.0829 - val_acc: 0.9814\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0334 - acc: 0.9903 - val_loss: 0.0837 - val_acc: 0.9820\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0302 - acc: 0.9911 - val_loss: 0.0974 - val_acc: 0.9801\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0303 - acc: 0.9915 - val_loss: 0.0849 - val_acc: 0.9818\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0273 - acc: 0.9919 - val_loss: 0.0931 - val_acc: 0.9800\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0275 - acc: 0.9928 - val_loss: 0.0969 - val_acc: 0.9823\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0254 - acc: 0.9929 - val_loss: 0.0893 - val_acc: 0.9836\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0242 - acc: 0.9934 - val_loss: 0.0975 - val_acc: 0.9837\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0968 - val_acc: 0.9848\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0193 - acc: 0.9947 - val_loss: 0.1001 - val_acc: 0.9830\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0219 - acc: 0.9941 - val_loss: 0.1144 - val_acc: 0.9827\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0196 - acc: 0.9947 - val_loss: 0.1009 - val_acc: 0.9844\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.1039 - val_acc: 0.9849\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0182 - acc: 0.9952 - val_loss: 0.1070 - val_acc: 0.9826\n",
      "Test loss: 0.10701886043086706\n",
      "Test accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = \"/Users/jedhassell/projects/jupyter/color\"\n",
    "validation_data_dir = \"/Users/jedhassell/projects/jupyter/validation\"\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
